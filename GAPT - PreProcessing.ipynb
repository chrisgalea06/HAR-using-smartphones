{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab020fb",
   "metadata": {
    "id": "10aff90f"
   },
   "source": [
    "# Code to Preprocess Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04cfcaac",
   "metadata": {
    "id": "e5325a4e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fft # site says you should use fft not fftpack\n",
    "# using rfft over fft is also faster as it only calculates the positive half of the freq domain (it's symmetric)\n",
    "# checkout https://realpython.com/python-scipy-fft/ for more info, and explanation of what fft exactly is\n",
    "# https://stackoverflow.com/questions/66675657/fast-fourier-transform-for-an-accelerometer-in-python also helped\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2d39d6",
   "metadata": {
    "id": "6c56dcd8"
   },
   "outputs": [],
   "source": [
    "#return sample rate - number of samples per second\n",
    "def getSampleRate(data):\n",
    "    seconds_elapsed = data['seconds_elapsed']\n",
    "    sample_rates = []\n",
    "    for s in seconds_elapsed:\n",
    "        sample_rate = 0\n",
    "        temp = int(s)\n",
    "        for i in range(len(seconds_elapsed)):\n",
    "            if int(seconds_elapsed[i]) == temp:\n",
    "                sample_rate+=1\n",
    "        sample_rates.append(sample_rate)\n",
    "        \n",
    "    return np.average(sample_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09719d35",
   "metadata": {
    "id": "64e062e2"
   },
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, nyq_freq, order=3):\n",
    "    normal_cutoff = float(cutoff) / nyq_freq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='lowpass')\n",
    "    return b, a\n",
    "\n",
    "#3rd order low pass butter worth filter\n",
    "def butter_lowpass_filter(data, cutoff_freq, nyq_freq, order=3):\n",
    "    b, a = butter_lowpass(cutoff_freq, nyq_freq, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3857f30b",
   "metadata": {
    "id": "cfe6af4e"
   },
   "outputs": [],
   "source": [
    "#build list of features for accelerometer data\n",
    "def pre_process_acc_data(data):\n",
    "    seconds_elapsed = data['seconds_elapsed'].to_numpy()\n",
    "    sample_rate = 0\n",
    "    for s in seconds_elapsed:\n",
    "        if int(s) == 1:\n",
    "            sample_rate+=1\n",
    "    signal_length = int(data['seconds_elapsed'].iloc[-1]) * sample_rate\n",
    "    data = data.drop(columns=['time', 'seconds_elapsed'])\n",
    "    \n",
    "    medDF = data.apply(signal.medfilt, kernel_size = 3)\n",
    "    \n",
    "    #Split into x,y,z after applying median filter\n",
    "    med_x = medDF['x']\n",
    "    med_y = medDF['y']\n",
    "    med_z = medDF['z']\n",
    "\n",
    "    #third order low-pass butterowrth filter\n",
    "    cutoff_frequency = 20\n",
    "\n",
    "    butterW_x = butter_lowpass_filter(med_x, cutoff_frequency, sample_rate/2)\n",
    "    butterW_y = butter_lowpass_filter(med_y, cutoff_frequency, sample_rate/2)\n",
    "    butterW_z = butter_lowpass_filter(med_z, cutoff_frequency, sample_rate/2)\n",
    "\n",
    "    #extracting gravity from accelerometer\n",
    "    cutoff_frequency = 0.3\n",
    "\n",
    "    tGravityAcc_x = butter_lowpass_filter(butterW_x, cutoff_frequency, sample_rate/2)\n",
    "    tGravityAcc_y = butter_lowpass_filter(butterW_y, cutoff_frequency, sample_rate/2)\n",
    "    tGravityAcc_z = butter_lowpass_filter(butterW_z, cutoff_frequency, sample_rate/2)\n",
    "\n",
    "    #extracting body from accelerometer\n",
    "    tBodyAcc_x = np.subtract(butterW_x, tGravityAcc_x)\n",
    "    tBodyAcc_y = np.subtract(butterW_y, tGravityAcc_y)\n",
    "    tBodyAcc_z = np.subtract(butterW_z, tGravityAcc_z)\n",
    "\n",
    "    #calculating magnitude\n",
    "    tBodyAccMag = np.sqrt(np.square(tBodyAcc_x) + np.square(tBodyAcc_y) + np.square(tBodyAcc_z))\n",
    "    tGravityAccMag = np.sqrt(np.square(tGravityAcc_x) + np.square(tGravityAcc_y) + np.square(tGravityAcc_z))\n",
    "\n",
    "\n",
    "    #jerk is change of in acceleration in a unit time\n",
    "    # old code\n",
    "    # you're not taking the difference in acceleration\n",
    "    # and you're not dividing by the time this change took place in\n",
    "    # seconds_elapsed will continue to increase, it is not the difference\n",
    "    #tBodyAccJerk_x = np.divide(tBodyAcc_x,seconds_elapsed)\n",
    "    #tBodyAccJerk_y = np.divide(tBodyAcc_y,seconds_elapsed)\n",
    "    #tBodyAccJerk_z = np.divide(tBodyAcc_z,seconds_elapsed)\n",
    "    \n",
    "    # if all 3 arrays are the same length then we can join these three loops into 1\n",
    "    tBodyAccJerk_x = []\n",
    "    for i in range(0, len(tBodyAcc_x)-1):\n",
    "        tBodyAccJerk_x.append((tBodyAcc_x[i+1]-tBodyAcc_x[i])/(seconds_elapsed[i+1]-seconds_elapsed[i]))\n",
    "    tBodyAccJerk_x.append(tBodyAccJerk_x[len(tBodyAccJerk_x)-1])\n",
    "    \n",
    "    \n",
    "    tBodyAccJerk_y = []\n",
    "    for i in range(0, len(tBodyAcc_y)-1):\n",
    "        tBodyAccJerk_y.append((tBodyAcc_y[i+1]-tBodyAcc_y[i])/(seconds_elapsed[i+1]-seconds_elapsed[i]))\n",
    "    tBodyAccJerk_y.append(tBodyAccJerk_y[len(tBodyAccJerk_y)-1])\n",
    " \n",
    "    tBodyAccJerk_z = []\n",
    "    for i in range(0, len(tBodyAcc_z)-1):\n",
    "        tBodyAccJerk_z.append((tBodyAcc_z[i+1]-tBodyAcc_z[i])/(seconds_elapsed[i+1]-seconds_elapsed[i]))\n",
    "    tBodyAccJerk_z.append(tBodyAccJerk_z[len(tBodyAccJerk_z)-1])\n",
    "        \n",
    "        \n",
    "    tBodyAccJerkMag = np.sqrt(np.square(tBodyAccJerk_x) + np.square(tBodyAccJerk_y) + np.square(tBodyAccJerk_z))\n",
    "\n",
    "    #FAST FOURIER TRANSFORM\n",
    "    #fbodyAcc-XYZ /FbodyAccJerk/ fbodyAccJerkMag\n",
    "    fBodyAcc_x = fft.fft(tBodyAcc_x)\n",
    "    fBodyAcc_x= np.abs(fBodyAcc_x)\n",
    "    #fBodyAcc_x = np.linspace(0, sample_rate, len(fBodyAcc_x)) if we want to plot these'll be the x axis\n",
    "    # but we need to change their name\n",
    "    \n",
    "    fBodyAcc_y = fft.fft(np.array(tBodyAcc_y))\n",
    "    fBodyAcc_y= np.abs(fBodyAcc_y)# this changes output from complex to real valued\n",
    "    #fBodyAcc_y = np.linspace(0, sample_rate, len(fBodyAcc_y))\n",
    "    \n",
    "    fBodyAcc_z = fft.fft(np.array(tBodyAcc_z))\n",
    "    fBodyAcc_z= np.abs(fBodyAcc_z)\n",
    "    #fBodyAcc_z = np.linspace(0, sample_rate, len(fBodyAcc_z))\n",
    "\n",
    "    fBodyAccMag = np.sqrt(np.square(fBodyAcc_x) + np.square(fBodyAcc_y) + np.square(fBodyAcc_z))\n",
    "\n",
    "    fBodyAccJerk_x = fft.fft(tBodyAccJerk_x)\n",
    "    fBodyAccJerk_x= np.abs(fBodyAccJerk_x)\n",
    "    #fBodyAccJerk_x = np.linspace(0, sample_rate, len(fBodyAccJerk_x))\n",
    "    \n",
    "    fBodyAccJerk_y = fft.fft(tBodyAccJerk_y)\n",
    "    fBodyAccJerk_y= np.abs(fBodyAccJerk_y)\n",
    "    #fBodyAccJerk_y = np.linspace(0, sample_rate, len(fBodyAccJerk_y))\n",
    "\n",
    "    fBodyAccJerk_z = fft.fft(tBodyAccJerk_z)\n",
    "    fBodyAccJerk_z= np.abs(fBodyAccJerk_z)\n",
    "    #fBodyAccJerk_z = np.linspace(0, sample_rate, len(fBodyAccJerk_z))\n",
    "    \n",
    "    fBodyAccJerkMag = np.sqrt(np.square(fBodyAccJerk_x) + np.square(fBodyAccJerk_y) + np.square(fBodyAccJerk_z))\n",
    "    \n",
    "    features = {\n",
    "\n",
    "        \"tBodyAcc_x\": tBodyAcc_x,\"tBodyAcc_y\": tBodyAcc_y,\"tBodyAcc_z\": tBodyAcc_z,\n",
    "        \"tGravityAcc_x\": tGravityAcc_x,\"tGravityAcc_y\": tGravityAcc_y,\"tGravityAcc_z\": tGravityAcc_z,\n",
    "        \"tBodyAccJerk_x\": tBodyAccJerk_x,\"tBodyAccJerk_y\": tBodyAccJerk_y,\"tBodyAccJerk_z\": tBodyAccJerk_z,\n",
    "        \n",
    "        \"tBodyAccMag\": tBodyAccMag,\n",
    "        \"tGravityAccMag\": tGravityAccMag,\n",
    "        \"tBodyAccJerkMag\": tBodyAccJerkMag,\n",
    "        \n",
    "        \"fBodyAcc_x\": fBodyAcc_x,\"fBodyAcc_y\": fBodyAcc_y,\"fBodyAcc_z\": fBodyAcc_z,\n",
    "        #\"tBodyAcc_x\": tBodyAcc_x,\"tBodyAcc_y\": tBodyAcc_y,\"tBodyAcc_z\": tBodyAcc_z,\n",
    "        \n",
    "        #\"tBodyAccJerkMag\":tBodyAccJerkMag,\n",
    "        \"fBodyAccJerkMag\":fBodyAccJerkMag,\n",
    "        \"fBodyAccMag\":tBodyAccJerkMag,\n",
    "        \n",
    "        \"fBodyAccJerk_x\": fBodyAccJerk_x,\"fBodyAccJerk_y\": fBodyAccJerk_y,\"fBodyAccJerk_z\": fBodyAccJerk_z\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a64d39",
   "metadata": {
    "id": "2226dd2f"
   },
   "outputs": [],
   "source": [
    "#build list of features for gyroscope data\n",
    "def pre_process_gyro_data(data):\n",
    "    seconds_elapsed = data['seconds_elapsed'].to_numpy()\n",
    "    sample_rate = 0\n",
    "    for s in seconds_elapsed:\n",
    "        if int(s) == 1:\n",
    "            sample_rate+=1\n",
    "    signal_length = int(data['seconds_elapsed'].iloc[-1]) * sample_rate\n",
    "    data = data.drop(columns=['time', 'seconds_elapsed'])\n",
    "    \n",
    "    medDF = data.apply(signal.medfilt, kernel_size = 3)\n",
    "    \n",
    "    #Split into x,y,z after applying median filter\n",
    "    med_x = medDF['x']\n",
    "    med_y = medDF['y']\n",
    "    med_z = medDF['z']\n",
    "\n",
    "    #third order low-pass butterowrth filter\n",
    "    cutoff_frequency = 20\n",
    "\n",
    "    butterW_x = butter_lowpass_filter(med_x, cutoff_frequency, sample_rate/2)\n",
    "    butterW_y = butter_lowpass_filter(med_y, cutoff_frequency, sample_rate/2)\n",
    "    butterW_z = butter_lowpass_filter(med_z, cutoff_frequency, sample_rate/2)\n",
    "\n",
    "    #extracting gravity from gyro data\n",
    "    cutoff_frequency = 0.3\n",
    "\n",
    "    tGravityGyro_x = butter_lowpass_filter(butterW_x, cutoff_frequency, sample_rate/2)\n",
    "    tGravityGyro_y = butter_lowpass_filter(butterW_y, cutoff_frequency, sample_rate/2)\n",
    "    tGravityGyro_z = butter_lowpass_filter(butterW_z, cutoff_frequency, sample_rate/2)\n",
    "\n",
    "    #extracting body from gyro data\n",
    "    tBodyGyro_x = np.subtract(butterW_x, tGravityGyro_x)\n",
    "    tBodyGyro_y = np.subtract(butterW_y, tGravityGyro_y)\n",
    "    tBodyGyro_z = np.subtract(butterW_z, tGravityGyro_z)\n",
    "\n",
    "    #calculating magnitude\n",
    "    tBodyGyroMag = np.sqrt(np.square(tBodyGyro_x) + np.square(tBodyGyro_y) + np.square(tBodyGyro_z))\n",
    "    tGravityGyroMag = np.sqrt(np.square(tGravityGyro_x) + np.square(tGravityGyro_y) + np.square(tGravityGyro_z))\n",
    "\n",
    "\n",
    "    #jerk is change of gyro data in unit time\n",
    "    #old code\n",
    "    #tBodyGyroJerk_x = np.divide(tBodyGyro_x,seconds_elapsed)\n",
    "    #tBodyGyroJerk_y = np.divide(tBodyGyro_y,seconds_elapsed)\n",
    "    #tBodyGyroJerk_z = np.divide(tBodyGyro_z,seconds_elapsed)\n",
    "    \n",
    "    # if all 3 arrays are the same length then we can join these three loops into 1\n",
    "    tBodyGyroJerk_x = []\n",
    "    for i in range(0, len(tBodyGyro_x)-1):\n",
    "        tBodyGyroJerk_x.append((tBodyGyro_x[i+1]-tBodyGyro_x[i])/(seconds_elapsed[i+1]-seconds_elapsed[i]))\n",
    "    tBodyGyroJerk_x.append(tBodyGyroJerk_x[len(tBodyGyroJerk_x)-1])\n",
    "        \n",
    "    tBodyGyroJerk_y = []\n",
    "    for i in range(0, len(tBodyGyro_y)-1):\n",
    "        tBodyGyroJerk_y.append((tBodyGyro_y[i+1]-tBodyGyro_y[i])/(seconds_elapsed[i+1]-seconds_elapsed[i]))\n",
    "    tBodyGyroJerk_y.append(tBodyGyroJerk_y[len(tBodyGyroJerk_y)-1])\n",
    "        \n",
    "        \n",
    "    tBodyGyroJerk_z = []\n",
    "    for i in range(0, len(tBodyGyro_z)-1):\n",
    "        tBodyGyroJerk_z.append((tBodyGyro_z[i+1]-tBodyGyro_z[i])/(seconds_elapsed[i+1]-seconds_elapsed[i]))\n",
    "    tBodyGyroJerk_z.append(tBodyGyroJerk_z[len(tBodyGyroJerk_z)-1])\n",
    "    \n",
    "    tBodyGyroJerkMag = np.sqrt(np.square(tBodyGyroJerk_x) + np.square(tBodyGyroJerk_y) + np.square(tBodyGyroJerk_z))\n",
    "\n",
    "    #FAST FOURIER TRANSFORM\n",
    "    #fbodyGyro-XYZ /FbodyGyroJerk/ fbodyGyroJerkMag\n",
    "    fBodyGyro_x = fft.fft(tBodyGyro_x)\n",
    "    fBodyGyro_x= np.abs(fBodyGyro_x)\n",
    "    #fBodyGyro_x = np.linspace(0, sample_rate, len(fBodyGyro_x)) same as for accelerometer above\n",
    "    \n",
    "    fBodyGyro_y = fft.fft(tBodyGyro_y)\n",
    "    fBodyGyro_y= np.abs(fBodyGyro_y)\n",
    "    #fBodyGyro_y = np.linspace(0, sample_rate, len(fBodyGyro_y))\n",
    "    \n",
    "    fBodyGyro_z = fft.fft(tBodyGyro_z)\n",
    "    fBodyGyro_z= np.abs(fBodyGyro_z)\n",
    "    #fBodyGyro_z = np.linspace(0, sample_rate, len(fBodyGyro_z))\n",
    "\n",
    "    fBodyGyroMag = np.sqrt(np.square(fBodyGyro_x) + np.square(fBodyGyro_y) + np.square(fBodyGyro_z))\n",
    "\n",
    "    fBodyGyroJerk_x = fft.fft(tBodyGyroJerk_x)\n",
    "    fBodyGyroJerk_x= np.abs(fBodyGyroJerk_x)\n",
    "    #fBodyGyroJerk_x = np.linspace(0, sample_rate, len(fBodyGyroJerk_x))\n",
    "    \n",
    "    fBodyGyroJerk_y = fft.fft(tBodyGyroJerk_y)\n",
    "    fBodyGyroJerk_y= np.abs(fBodyGyroJerk_y)\n",
    "    #fBodyGyroJerk_y = np.linspace(0, sample_rate, len(fBodyGyroJerk_y))\n",
    "\n",
    "    fBodyGyroJerk_z = fft.fft(tBodyGyroJerk_z)\n",
    "    fBodyGyroJerk_z= np.abs(fBodyGyroJerk_z)\n",
    "    #fBodyGyroJerk_z = np.linspace(0, sample_rate, len(fBodyGyroJerk_z))\n",
    "    \n",
    "    fBodyGyroJerkMag = np.sqrt(np.square(fBodyGyroJerk_x) + np.square(fBodyGyroJerk_y) + np.square(fBodyGyroJerk_z))\n",
    "    \n",
    "    features = {\n",
    "        \"tBodyGyro_x\": tBodyGyro_x,\"tBodyGyro_y\": tBodyGyro_y,\"tBodyGyro_z\": tBodyGyro_z,\n",
    "        \"tGravityGyro_x\": tGravityGyro_x,\"tGravityGyro_y\": tGravityGyro_y,\"tGravityGyro_z\": tGravityGyro_z,\n",
    "        \"tBodyGyroJerk_x\": tBodyGyroJerk_x,\"tBodyGyroJerk_y\": tBodyGyroJerk_y,\"tBodyGyroJerk_z\": tBodyGyroJerk_z,\n",
    "        \n",
    "        \"tBodyGyroMag\": tBodyGyroMag,\n",
    "        \"tGravityGyroMag\": tGravityGyroMag,\n",
    "        \"tBodyGyroJerkMag\": tBodyGyroJerkMag,\n",
    "        \n",
    "        \"fBodyGyro_x\": fBodyGyro_x,\"fBodyGyro_y\": fBodyGyro_y,\"fBodyGyro_z\": fBodyGyro_z,\n",
    "        #\"tBodyGyro_x\": tBodyGyro_x,\"tBodyGyro_y\": tBodyGyro_y,\"tBodyGyro_z\": tBodyGyro_z,\n",
    "        \n",
    "        #\"tBodyGyroJerkMag\":tBodyGyroJerkMag,\n",
    "        \"fBodyGyroJerkMag\":fBodyGyroJerkMag,\n",
    "        \"fBodyGyroMag\":tBodyGyroJerkMag\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8481b15",
   "metadata": {
    "id": "ea90b84d"
   },
   "source": [
    "### Set of variables to be estimated from the list of features\n",
    "- mean():     Mean value\n",
    "- std():      Standard deviation\n",
    "- mad():      Median absolute deviation \n",
    "- max():      Largest value in array\n",
    "- min():      Smallest value in array\n",
    "- iqr():      Interquartile range \n",
    "- entropy():  Signal entropy\n",
    "- skewness(): skewness of the frequency domain signal \n",
    "- kurtosis(): kurtosis of the frequency domain signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3c1cc86",
   "metadata": {
    "id": "af4b2ec0"
   },
   "outputs": [],
   "source": [
    "#return activity name and environment number \n",
    "#(subject is excluded as it is already known which subject performed which activity)\n",
    "\n",
    "#example file name: Data Collection\\Jogging\\Jogging_1.7_(1)  \n",
    "def get_details(filename):\n",
    "    if 'Walking_Upstairs' in filename:\n",
    "        return get_details_updown(filename)\n",
    "    if 'Walking_Downstairs' in filename:\n",
    "        return get_details_updown(filename)\n",
    "    details = filename.split('\\\\')\n",
    "    details = details[2]                 #Jogging_1.7_(1)\n",
    "    details = details.split('_')\n",
    "    activity = details[0]                #Jogging\n",
    "    env = details[1].split('.')[1]       #7\n",
    "    return activity, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6dfbda2",
   "metadata": {
    "id": "59408ddf"
   },
   "outputs": [],
   "source": [
    "#this method is intended to have the same function as `get_details()` but is applied only for Walking UpDown Stairs activity\n",
    "\n",
    "#example file name: Data Collection\\Laying and Walking Up/Down Stairs\\Walking_Upstairs_3.7.5_(1)\n",
    "def get_details_updown(filename):\n",
    "    details = filename.split('\\\\')\n",
    "    details = details[2]                          #Walking_Upstairs_3.7.5_(1)\n",
    "    details = details.split('_')\n",
    "#    activity = details[0]+ \" \" + details[1]       #Walking_Upstairs\n",
    "    activity = details[0]+ \" Up/Down Stairs\" \n",
    "    \n",
    "    \n",
    "    temp_env = details[2].split('.')\n",
    "    if len(temp_env) == 3:\n",
    "        env = temp_env[1] + '.' + temp_env[2]     #7.5\n",
    "    else: \n",
    "        env = temp_env[1]                         #or 7 if there is only (..._3.7_(1)\n",
    "    return activity, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b32fc5",
   "metadata": {
    "id": "a9c1908c"
   },
   "outputs": [],
   "source": [
    "def dict_add(obj,key,value):\n",
    "    obj[key]=value\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36363bbc",
   "metadata": {
    "id": "6ab037ef"
   },
   "source": [
    "`def read_acc_data(listOfAcc):\n",
    "    for f in listOfAcc:\n",
    "        data = pd.read_csv(f) \n",
    "        features = pre_process_acc_data(data)\n",
    "    return features`   \n",
    "\n",
    "`def read_gyro_data(listOfGyro):\n",
    "    for f in listOfGyro:\n",
    "        data = pd.read_csv(f) \n",
    "        features = pre_process_gyro_data(data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667ddae5",
   "metadata": {
    "id": "835e1a87"
   },
   "outputs": [],
   "source": [
    "#getting list of filenames \n",
    "listOfFiles = []\n",
    "for (root,dirs,files) in os.walk('Data Collection'):\n",
    "    for name in files: #for each file found\n",
    "        if name != 'Metadata.csv': \n",
    "        #metadata includes the details of the smartphone used to record data - \n",
    "        #this is not needed\n",
    "            listOfFiles.append(os.path.join(root, name))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0690e71",
   "metadata": {
    "id": "fc6cfb68"
   },
   "outputs": [],
   "source": [
    "#Returns a list of Column names with features + the estimated variables (std, mean, max ...)\n",
    "def get_col_names(df,string):\n",
    "    listOfCols_final = []\n",
    "    listOfCols = df.columns.tolist()\n",
    "\n",
    "    for i in range(len(listOfCols)):\n",
    "        listOfCols_final.append(listOfCols[i] + \"_\" + string)\n",
    "        \n",
    "    return listOfCols_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a69a543e",
   "metadata": {
    "id": "1b634f11"
   },
   "outputs": [],
   "source": [
    "def get_iqr_val(lower,upper):\n",
    "    return np.subtract(upper,lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d7c1b39",
   "metadata": {
    "id": "270b52b9"
   },
   "outputs": [],
   "source": [
    "def get_entropy_val(features):\n",
    "    entropy_values = []\n",
    "    for key in features:\n",
    "        #calculate entropy for each element in features\n",
    "        pd_series = pd.Series(features[key])\n",
    "        counts = pd_series.value_counts()\n",
    "        value = entropy(counts)\n",
    "\n",
    "        entropy_values.append(value)\n",
    "    return entropy_values\n",
    "\n",
    "#.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "276530da",
   "metadata": {
    "id": "6312c7a0"
   },
   "outputs": [],
   "source": [
    "#to extract features for skweness and kurtosis\n",
    "def prepare_features(features):\n",
    "    new_features = {}\n",
    "    for key in features:\n",
    "        if 'fBodyAccMag' in key or 'fBodyAccJerk_' in key or 'fBodyGyro_' in key or 'fBodyAcc_' in key:\n",
    "            dict_add(new_features,key,features[key])\n",
    "            \n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f907b54",
   "metadata": {
    "id": "4d56404f"
   },
   "source": [
    "__Skewness and kurtosis are only estimated on the following variables:__\n",
    "- fbodyaccmag\n",
    "- fbodygyroxyz\n",
    "- fbodyaccjerkxyz\n",
    "- fbodyaccxyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ffcd39",
   "metadata": {
    "id": "af60190a"
   },
   "outputs": [],
   "source": [
    "final_listOfDicts = []\n",
    "\n",
    "\n",
    "#returns a list of dictionaries with all the values - final\n",
    "def read_all_files(listOfFiles):\n",
    "    #list of files includes both gyro and acc data\n",
    "    for f in listOfFiles:\n",
    "        activity,env = get_details(f)\n",
    "        #set title as file name\n",
    "        nameOfFile = f\n",
    "        data = pd.read_csv(f) \n",
    "        if 'Accelerometer.csv' in f: \n",
    "            features = pre_process_acc_data(data)\n",
    "            # if accelerometer: start new row\n",
    "            listOfCols_final = []\n",
    "            result = []\n",
    "            listOfCols_final.append('Activity')\n",
    "            listOfCols_final.append('Environment')\n",
    "            result.append(activity)\n",
    "            result.append(env)\n",
    "            final = {}\n",
    "        if 'Gyroscope.csv' in f: \n",
    "            features = pre_process_gyro_data(data)\n",
    "        \n",
    "        feautures_df = pd.DataFrame.from_dict(features)\n",
    "       \n",
    "        #for median,max,min std\n",
    "        timeDomainMetrics = feautures_df.describe()\n",
    "        for num in [1,2,3,7]:\n",
    "            result.extend(timeDomainMetrics.iloc[num].tolist())\n",
    "        listOfCols_final.extend(get_col_names(timeDomainMetrics,\"mean\"))\n",
    "        listOfCols_final.extend(get_col_names(timeDomainMetrics,\"std\"))\n",
    "        listOfCols_final.extend(get_col_names(timeDomainMetrics,\"min\"))\n",
    "        listOfCols_final.extend(get_col_names(timeDomainMetrics,\"max\"))\n",
    "        \n",
    "        \n",
    "        #for iqr\n",
    "        listOfCols_final.extend(get_col_names(timeDomainMetrics,\"iqr\"))       \n",
    "        result.extend(get_iqr_val(timeDomainMetrics.iloc[4].tolist(),timeDomainMetrics.iloc[6].tolist()))\n",
    "    \n",
    "    \n",
    "        #for mean abs dev\n",
    "        mad_vals = feautures_df.mad()\n",
    "        listOfCols_final.extend(get_col_names(timeDomainMetrics,\"mad\"))  \n",
    "        result.extend(mad_vals)\n",
    "        \n",
    "        \n",
    "        #for entropy - lack of order or predictability; gradual decline into disorder\n",
    "        ent_vals = get_entropy_val(features)\n",
    "        listOfCols_final.extend(get_col_names(timeDomainMetrics,\"entropy\"))\n",
    "        result.extend(ent_vals)\n",
    "        \n",
    "        \n",
    "        f_features = prepare_features(features) #features used for skewness and kurtosis\n",
    "        f_features_df = pd.DataFrame.from_dict(f_features)\n",
    "        \n",
    "        #for skewness\n",
    "        skew_vals = f_features_df.skew()\n",
    "        listOfCols_final.extend(get_col_names(f_features_df,\"skew\"))\n",
    "        result.extend(skew_vals)\n",
    "        \n",
    "        \n",
    "        #for kurtosis\n",
    "        kurt_vals = f_features_df.kurtosis()\n",
    "        listOfCols_final.extend(get_col_names(f_features_df,\"kurt\"))\n",
    "        result.extend(kurt_vals)\n",
    "\n",
    "        #print(len(listOfCols_final))\n",
    "        if 'Gyroscope.csv' in f:      \n",
    "            for i in range(len(listOfCols_final)):\n",
    "                dict_add(final,listOfCols_final[i],result[i])\n",
    "            final_listOfDicts.append(final)\n",
    "            \n",
    "            \n",
    "    return final_listOfDicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8769041",
   "metadata": {
    "id": "24752c8a",
    "outputId": "6fe077f6-fe92-4964-d4f1-c59a839a8099",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_dict = read_all_files(listOfFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daa11b9f",
   "metadata": {
    "id": "29147e29",
    "outputId": "6e3a64cb-370c-4204-a9cd-19ef368006d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 281)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(final_dict) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d4ca5ce",
   "metadata": {
    "id": "4dba5d04"
   },
   "outputs": [],
   "source": [
    "train=df.sample(frac=0.8,random_state=250) #random state is a seed value\n",
    "test=df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2896628c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>Environment</th>\n",
       "      <th>tBodyAcc_x_mean</th>\n",
       "      <th>tBodyAcc_y_mean</th>\n",
       "      <th>tBodyAcc_z_mean</th>\n",
       "      <th>tGravityAcc_x_mean</th>\n",
       "      <th>tGravityAcc_y_mean</th>\n",
       "      <th>tGravityAcc_z_mean</th>\n",
       "      <th>tBodyAccJerk_x_mean</th>\n",
       "      <th>tBodyAccJerk_y_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyGyro_y_entropy</th>\n",
       "      <th>fBodyGyro_z_entropy</th>\n",
       "      <th>fBodyGyroJerkMag_entropy</th>\n",
       "      <th>fBodyGyroMag_entropy</th>\n",
       "      <th>fBodyGyro_x_skew</th>\n",
       "      <th>fBodyGyro_y_skew</th>\n",
       "      <th>fBodyGyro_z_skew</th>\n",
       "      <th>fBodyGyro_x_kurt</th>\n",
       "      <th>fBodyGyro_y_kurt</th>\n",
       "      <th>fBodyGyro_z_kurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Walking Up/Down Stairs</td>\n",
       "      <td>6.4</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>-0.023978</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>-0.024484</td>\n",
       "      <td>0.179190</td>\n",
       "      <td>-0.081896</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.012094</td>\n",
       "      <td>...</td>\n",
       "      <td>8.157283</td>\n",
       "      <td>8.157283</td>\n",
       "      <td>8.157283</td>\n",
       "      <td>8.850032</td>\n",
       "      <td>19.068029</td>\n",
       "      <td>26.896403</td>\n",
       "      <td>23.455451</td>\n",
       "      <td>443.170211</td>\n",
       "      <td>981.912007</td>\n",
       "      <td>694.778330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Walking Up/Down Stairs</td>\n",
       "      <td>6.4</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>-0.017839</td>\n",
       "      <td>-0.001046</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.165759</td>\n",
       "      <td>-0.114990</td>\n",
       "      <td>0.017374</td>\n",
       "      <td>-0.024135</td>\n",
       "      <td>...</td>\n",
       "      <td>7.892337</td>\n",
       "      <td>7.892337</td>\n",
       "      <td>7.892337</td>\n",
       "      <td>8.584967</td>\n",
       "      <td>25.019693</td>\n",
       "      <td>16.702488</td>\n",
       "      <td>20.045304</td>\n",
       "      <td>854.299906</td>\n",
       "      <td>457.956971</td>\n",
       "      <td>574.135297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Falling</td>\n",
       "      <td>25</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>-0.025026</td>\n",
       "      <td>-0.598838</td>\n",
       "      <td>-0.501942</td>\n",
       "      <td>-0.387593</td>\n",
       "      <td>-0.263061</td>\n",
       "      <td>-0.065136</td>\n",
       "      <td>...</td>\n",
       "      <td>6.873005</td>\n",
       "      <td>6.873005</td>\n",
       "      <td>6.873005</td>\n",
       "      <td>7.565075</td>\n",
       "      <td>4.983377</td>\n",
       "      <td>6.408874</td>\n",
       "      <td>6.201328</td>\n",
       "      <td>28.101364</td>\n",
       "      <td>50.730299</td>\n",
       "      <td>42.572040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Walking Up/Down Stairs</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.024677</td>\n",
       "      <td>-0.012084</td>\n",
       "      <td>0.005114</td>\n",
       "      <td>0.055345</td>\n",
       "      <td>0.142871</td>\n",
       "      <td>-0.089958</td>\n",
       "      <td>0.071191</td>\n",
       "      <td>-0.052932</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000298</td>\n",
       "      <td>8.000298</td>\n",
       "      <td>8.000298</td>\n",
       "      <td>8.693097</td>\n",
       "      <td>30.456696</td>\n",
       "      <td>17.711650</td>\n",
       "      <td>24.487421</td>\n",
       "      <td>1189.201047</td>\n",
       "      <td>467.153788</td>\n",
       "      <td>810.408642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Jogging</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.025575</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>0.109328</td>\n",
       "      <td>1.266131</td>\n",
       "      <td>2.914257</td>\n",
       "      <td>-3.793095</td>\n",
       "      <td>-0.028779</td>\n",
       "      <td>-0.063142</td>\n",
       "      <td>...</td>\n",
       "      <td>8.036200</td>\n",
       "      <td>8.036200</td>\n",
       "      <td>8.036200</td>\n",
       "      <td>8.729011</td>\n",
       "      <td>10.524501</td>\n",
       "      <td>15.517435</td>\n",
       "      <td>9.807294</td>\n",
       "      <td>148.584406</td>\n",
       "      <td>409.558375</td>\n",
       "      <td>123.857022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Laying</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.056488</td>\n",
       "      <td>0.012439</td>\n",
       "      <td>-0.083881</td>\n",
       "      <td>-0.009123</td>\n",
       "      <td>-0.003118</td>\n",
       "      <td>...</td>\n",
       "      <td>8.101631</td>\n",
       "      <td>8.101631</td>\n",
       "      <td>8.101631</td>\n",
       "      <td>8.794463</td>\n",
       "      <td>6.546909</td>\n",
       "      <td>5.675385</td>\n",
       "      <td>9.142245</td>\n",
       "      <td>49.458135</td>\n",
       "      <td>35.174480</td>\n",
       "      <td>105.722129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Walking Up/Down Stairs</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>-0.002455</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.057085</td>\n",
       "      <td>0.182446</td>\n",
       "      <td>-0.146083</td>\n",
       "      <td>0.065104</td>\n",
       "      <td>-0.147402</td>\n",
       "      <td>...</td>\n",
       "      <td>8.064274</td>\n",
       "      <td>8.064274</td>\n",
       "      <td>8.064274</td>\n",
       "      <td>8.757094</td>\n",
       "      <td>20.095172</td>\n",
       "      <td>17.008845</td>\n",
       "      <td>26.262620</td>\n",
       "      <td>524.885492</td>\n",
       "      <td>399.225871</td>\n",
       "      <td>845.249341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Walking Up/Down Stairs</td>\n",
       "      <td>9</td>\n",
       "      <td>0.019292</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>0.020037</td>\n",
       "      <td>0.113986</td>\n",
       "      <td>0.179275</td>\n",
       "      <td>-0.046772</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.037902</td>\n",
       "      <td>...</td>\n",
       "      <td>7.959572</td>\n",
       "      <td>7.959572</td>\n",
       "      <td>7.959572</td>\n",
       "      <td>8.652356</td>\n",
       "      <td>38.875812</td>\n",
       "      <td>20.533755</td>\n",
       "      <td>29.786797</td>\n",
       "      <td>1768.120008</td>\n",
       "      <td>635.361762</td>\n",
       "      <td>1157.887044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Falling</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.006026</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>-0.455038</td>\n",
       "      <td>-0.715126</td>\n",
       "      <td>-0.111975</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.039608</td>\n",
       "      <td>...</td>\n",
       "      <td>7.028952</td>\n",
       "      <td>7.028952</td>\n",
       "      <td>7.028952</td>\n",
       "      <td>7.721178</td>\n",
       "      <td>5.303515</td>\n",
       "      <td>6.782456</td>\n",
       "      <td>6.994913</td>\n",
       "      <td>31.853616</td>\n",
       "      <td>55.712232</td>\n",
       "      <td>55.142558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Sitting</td>\n",
       "      <td>13</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>-0.001840</td>\n",
       "      <td>-0.000641</td>\n",
       "      <td>-0.022233</td>\n",
       "      <td>0.107782</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>-0.004041</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>...</td>\n",
       "      <td>7.315014</td>\n",
       "      <td>7.315014</td>\n",
       "      <td>7.315014</td>\n",
       "      <td>8.007239</td>\n",
       "      <td>3.520094</td>\n",
       "      <td>5.523751</td>\n",
       "      <td>4.030148</td>\n",
       "      <td>12.575353</td>\n",
       "      <td>36.728696</td>\n",
       "      <td>18.264043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Activity Environment  tBodyAcc_x_mean  tBodyAcc_y_mean  \\\n",
       "232  Walking Up/Down Stairs         6.4        -0.003247        -0.023978   \n",
       "150  Walking Up/Down Stairs         6.4        -0.003406        -0.017839   \n",
       "24                  Falling          25         0.006947         0.003593   \n",
       "197  Walking Up/Down Stairs         9.5         0.024677        -0.012084   \n",
       "45                  Jogging          10        -0.025575         0.010588   \n",
       "..                      ...         ...              ...              ...   \n",
       "92                   Laying          13         0.000110        -0.000386   \n",
       "252  Walking Up/Down Stairs         7.4         0.012513        -0.002455   \n",
       "208  Walking Up/Down Stairs           9         0.019292        -0.014177   \n",
       "12                  Falling          23        -0.006026         0.009920   \n",
       "290                 Sitting          13         0.001606        -0.001840   \n",
       "\n",
       "     tBodyAcc_z_mean  tGravityAcc_x_mean  tGravityAcc_y_mean  \\\n",
       "232         0.010634           -0.024484            0.179190   \n",
       "150        -0.001046            0.019053            0.165759   \n",
       "24         -0.025026           -0.598838           -0.501942   \n",
       "197         0.005114            0.055345            0.142871   \n",
       "45          0.109328            1.266131            2.914257   \n",
       "..               ...                 ...                 ...   \n",
       "92          0.000497            0.056488            0.012439   \n",
       "252         0.005196            0.057085            0.182446   \n",
       "208         0.020037            0.113986            0.179275   \n",
       "12          0.013106           -0.455038           -0.715126   \n",
       "290        -0.000641           -0.022233            0.107782   \n",
       "\n",
       "     tGravityAcc_z_mean  tBodyAccJerk_x_mean  tBodyAccJerk_y_mean  ...  \\\n",
       "232           -0.081896             0.004629             0.012094  ...   \n",
       "150           -0.114990             0.017374            -0.024135  ...   \n",
       "24            -0.387593            -0.263061            -0.065136  ...   \n",
       "197           -0.089958             0.071191            -0.052932  ...   \n",
       "45            -3.793095            -0.028779            -0.063142  ...   \n",
       "..                  ...                  ...                  ...  ...   \n",
       "92            -0.083881            -0.009123            -0.003118  ...   \n",
       "252           -0.146083             0.065104            -0.147402  ...   \n",
       "208           -0.046772             0.011292             0.037902  ...   \n",
       "12            -0.111975             0.030000             0.039608  ...   \n",
       "290            0.002237            -0.004041            -0.008227  ...   \n",
       "\n",
       "     fBodyGyro_y_entropy  fBodyGyro_z_entropy  fBodyGyroJerkMag_entropy  \\\n",
       "232             8.157283             8.157283                  8.157283   \n",
       "150             7.892337             7.892337                  7.892337   \n",
       "24              6.873005             6.873005                  6.873005   \n",
       "197             8.000298             8.000298                  8.000298   \n",
       "45              8.036200             8.036200                  8.036200   \n",
       "..                   ...                  ...                       ...   \n",
       "92              8.101631             8.101631                  8.101631   \n",
       "252             8.064274             8.064274                  8.064274   \n",
       "208             7.959572             7.959572                  7.959572   \n",
       "12              7.028952             7.028952                  7.028952   \n",
       "290             7.315014             7.315014                  7.315014   \n",
       "\n",
       "     fBodyGyroMag_entropy  fBodyGyro_x_skew  fBodyGyro_y_skew  \\\n",
       "232              8.850032         19.068029         26.896403   \n",
       "150              8.584967         25.019693         16.702488   \n",
       "24               7.565075          4.983377          6.408874   \n",
       "197              8.693097         30.456696         17.711650   \n",
       "45               8.729011         10.524501         15.517435   \n",
       "..                    ...               ...               ...   \n",
       "92               8.794463          6.546909          5.675385   \n",
       "252              8.757094         20.095172         17.008845   \n",
       "208              8.652356         38.875812         20.533755   \n",
       "12               7.721178          5.303515          6.782456   \n",
       "290              8.007239          3.520094          5.523751   \n",
       "\n",
       "     fBodyGyro_z_skew  fBodyGyro_x_kurt  fBodyGyro_y_kurt  fBodyGyro_z_kurt  \n",
       "232         23.455451        443.170211        981.912007        694.778330  \n",
       "150         20.045304        854.299906        457.956971        574.135297  \n",
       "24           6.201328         28.101364         50.730299         42.572040  \n",
       "197         24.487421       1189.201047        467.153788        810.408642  \n",
       "45           9.807294        148.584406        409.558375        123.857022  \n",
       "..                ...               ...               ...               ...  \n",
       "92           9.142245         49.458135         35.174480        105.722129  \n",
       "252         26.262620        524.885492        399.225871        845.249341  \n",
       "208         29.786797       1768.120008        635.361762       1157.887044  \n",
       "12           6.994913         31.853616         55.712232         55.142558  \n",
       "290          4.030148         12.575353         36.728696         18.264043  \n",
       "\n",
       "[300 rows x 281 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "472d9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('Processed Data/train.csv',index=False)\n",
    "test.to_csv('Processed Data/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f37004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GAPT - PreProcessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
